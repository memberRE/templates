# 作业一：简单神经网络

## 任务

训练一个神经网络用来判断手写的数字

## 阅读代码中的疑问

- BP神经网络中的层数和每层的节点数应该如何确定？



- 在初始化的时候为何要正太分布，且方差为啥要是$1/\sqrt{(node)}$.

  答：首先假设我们输入的每个特征都服从均值为0，方差为1的分布，（**因为数据大部分情况下都要进行归一化处理**），为了使网络中的信息更好的传递，每一层的特征的方差应该尽可能相等**（为啥啊为啥啊QAQ）**，

  $var(s) = var(\sum_i^n w_i x_i)$

  ,$var(s) = \sum_i^n E(w_i^2) E(x_i^2) - (E(x_i))^2 (E(w_i))^2$,

  $var(s) = \sum_i^n (E(w_i))^2 var(x_i) + (E(x_i))^2 var(w_i) + var(x_i) var(w_i)$

  由于输入数据的均值为0，初始化权值的均值也选择为0**(？？？)**，因为x的方差为1，代入数据解得$var(w) = 1/n$.

  所以标准差为$\frac{1}{\sqrt{n}}$

- 如何选择隐藏层的层数和节点数

  答：**在神经网络中，当且仅当数据非线性分离时才需要隐藏层！**，（想一下老师的ppt，在用感知机计算与或非的时候只有一层，还有那个坐标系的图，在计算异或的时候才需要两层）

  - **没有隐藏层**：仅能够表示线性可分函数或决策

  - **隐藏层数=1**：可以拟合任何“包含从一个有限空间到另一个有限空间的连续映射”的函数

  - **隐藏层数=2**：搭配适当的激活函数可以表示任意精度的任意决策边界，并且可以拟合任何精度的任何平滑映射

  - **隐藏层数>2**：多出来的隐藏层可以学习复杂的描述（某种自动特征工程）

  关于数量问题，有一个经验公式$N_h = \frac{N_s}{a*(N_i+N_o)}$,a为常数，一般取2~10，$N_s$为样本数量.

- 为何处理数据的时候会用$\frac{val}{MAX_{val}}*0.99+0.01$,是为了不希望出现过于接近0的数字？为啥呢？

  答：